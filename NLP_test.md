## 자연어 처리

### 자연어 처리(NLP)란

> 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 모사할 수 있도록 연구하고 이를 구현하는 인공지능 주유 분야 중 하나
>
> 인간의 언어로 명령을 내리면 기계가 자연어 처리를 통해 이해하여 처리하고, 그 결과를 사용자에게 전달한다.



### 왜 필요한가

비정형 데이터의 중요성

- 전 세계에서 생성되는 데이터 7,80%가 비정형 데이터(뉴스, SNS, 블로그, 기타문서 등)

온라인 데이터의 중요성

- 온라인 평판관리(ORM)의 중요성
- 분석 대상과 관련된 비정형 데이터를 수집하고 자연어 처리를 통해서 문서 내 인사이트 도출 가능

소통 패러다임의 변화

- 인공지능 스피커, 인공지능 챗봇 등 인터페이스가 대화형으로 변화



### 특히 한국어가 어려운 이유

언어의 모호성; 동음이의어(동형이의어, 동음이형어)/ 다의어

특히 한국어가 어려운 이유

- 구어와 문어의 차이
- 띄어쓰기에 어려움
- 청자와 화자의 관계에 따른 높임법
- 동음이의어, 운율적 요소에 따른 의미변화
- 주어 서술어 목적어 등의 빈번한 생략



### 일상 속 자연어 처리 활용 사례

정보 검색, QA시스템, 문서 자동 분류, 신문기사 클러스터링, 대화형 Agent 등

검색 엔진, 스팸 메일 분류, 인공지능 비서, 문법 검사기, 교육, SNS 내 인지도 분석, 호감도 분석



### 자연어 처리 분석 절차

1. 데이터 수집 단계

- 데이터 수집

- 데이터 정제



___



2. 텍스트 전처리 단계

- 토큰화

  - 문장 토큰화

    문장 기준으로 토큰화

    마침표, 느낌표, 물음표 등으로 분류

  - 단어 토큰화

    영문의 경우 공백을 기준으로 분리하면 유의미한 토큰화가 가능 split()

    한글의 경우 품사를 고려한 토큰화가 필요

  - 형태소 분석

    문장을 형태소(언어 뜻을 가진 가장 작은 말의 단위)로 분리하는 작업

- 품사 부착(POS tagging)

- 원형 복원

  분리한 토큰을 표준화 하는 작업

  - 어간 추출(stemming)
  - 표제어 추출(Lemmatization)

- 불용어 처리

  의미가 없는 단어 토큰을 제거하는 작업



___



3. 텍스트 분석 단계

- 주제어 찾기
- 문서 요약
- 문서 분류
- 감성 분석



___



4. 시각화 단계

Word Cloud, Sentiment Pie Chart등



### 자연어 처리에서 데이터를 지칭하는 말

말뭉치(corpus)



### 토큰화

#### 형태소, 원형복원, 어간추출



### 유사도 계산

- 벡터간 직진거리 -__유클리디언__
- 두 벡터 사이의 각(코사인)을 이용 - __코사인 유사도__
- 겹치는 토큰의 비율 - __자카드 유사도__
- 두 문자열이 얼마나 다른지를 나타내는 거리 중 하나 - __레벤슈타인 유사도__



### 자카드 유사도(계산)

|A∩B| / |A∪B|



### 자연어 처리를 하기 위해 숫자화: 원핫-인코딩

원핫-인코딩은 단어를 숫자로 표현하고자 할 때 적용할 수 있는 간단한 방법론

한계점

- 차원 크기의 문제: 단어의 수만큼 차원이 필요하다
- 의미를 담지 못하는 문제: 원핫 벡터간 코사인 유사도는 모두 0, 의미를 분간하기 어렵다



### 자연어 처리를 하기 위해 숫자화: 단어 임베딩

단어 임베딩은 단어의 의미를 간직하는 밀집 벡터(Dense Vector)로 표현하는 방법

차원의 문제를 밀집 벡터로 해결했다

__분포가설__ ('같은 문맥에서 등장하는 단어는 유사한 의미를 지닌다')을 전제



### BoW를 하나의 행렬로: TDM

__BoW:__ 문서 내 단어 출현 순서는 무시. 빈도수 기반으로 문서를 표현

__TDM:__ BoW 중 하나, 문서에 등장하는 각 단어 빈도를 행렬로 표현

|       | 문서1 | 문서2 |
| ----- | ----- | ----- |
| 단어1 |       |       |
| 단어2 |       |       |
| 단어3 |       |       |

 

#### 한계

- 단어의 순서를 고려하지 않음
- Sparse함. 벡터 공간의 낭비, 연산 비효율성 초래
- 단어 빈도수가 반드시 중요도를 의미하는 것은 아니다. (ex) the

___

이를 보완하기 위해 ___TF-IDF___ 사용 



### 핵심 키워드 추출

> 문서에서 가장 중요한 단어를 자동으로 추출하는 과정

#### 필요성

- 대량 데이터 처리 가능
- 추출의 일관성
- 실시간 분석 가능



### 텍스트 랭크

> 기본 아이디어는 구글의 PageRank

그래프 기반 Ranking 모델로 키워드와 문장 추출을 위한 비지도 학습 방법을 제안한다.

하나의 vertex가 다른 vertex에 연결되면 "투표" 혹은 "추천"한 것이다. 많은 득표를 한 vertex가 중요한 vertex다.  





### 문서 분류

#### 나이브 베이즈 분류

> 특성들 사이의 독립을 가정하는 베이즈 정리(사전 확률과 사후확률 사이의 관계를 조건부 확률을 이용해 계산하는 확률 이론)를 적용한 확률 분류기의 일종
>
> > _베이즈 정리_
> >
> > - 사전 확률(관찰 가능): 이미 알고 있는 사건이 발생할 확률 P(A)
> > - 우도(likelihood probability)(관찰 가능): 이미 알고 있는 사건이 발생한다는 조건 하에 다른 사건이 발생할 확률 P(B|A) = P(A∩B) / P(A)
> > - 사후 확률: 사전확률과 우도를 통해서 알게되는 조건부 확률 P(A|B) = P(B|A)P(A) / P(A)P(B|A) + P(A')P(B|A')

사용자가 사전에 정의한 범주를 학습하여 새로운 문서가 입력되었을 때 범주 분류를 예측



- 장점

  - 범주형 변수 처리
  - 단순성, 계산의 효율성
  - 좋은 분류성능

- 단점

  - 많은 데이터 필요
  - 값이 0일 확률 처리(Laplace smoothing: 분자와 분모에 일정 상수를 더하여 신규 단어가 출현했을 때 0으로 계산되는 것을 방지)

  

### 선형대수학

#### 차원 축소

> 차원이 증가할 수록 데이터의 표현이 어렵고 연산이 어렵다(차원의 저주).
>
> 같은 정보를 표현하는데 낮은 차원을 사용하여 정보를 표현하는 것을 __차원축소__라고 함

- 차원 축소시 정보의 손실이 발생! 따라서 __정보 손실을 최소화__하는 것이 가장 중요하다

- 주성분 분석(PCA)

  다차원 데이터의 정보를 가능한 한 손실 없이 저차원 공간에 압축하는 것

  - 첫번째 주성분 축 생성
    - 분산이 가장 큰(데이터가 가장 넓게 퍼져있는) 방향을 구한다
    - 그 방향으로 첫번째 축을 만든다.
  - 두번째 주성분 축 생성
    - 첫번째 축과 직교하며, 분산이 두번째로 큰 방향을 구한다.
    - 그 방향으로 두번째 축을 만든다.

- 고유값 분해

- 특이값 분해(SVD)



### 토픽 모델링 분석

> 문서는 여러 주제(topic)로 구성되어 있다. topic은 단어의 집합이다.

#### 잠재 디리클레 할당

주어진 문서에 대해 어떤 주제가 존재하는 지에 대한 확률모형

##### 절차

1. D개의 전체 문서에 k개 토픽이 분포되었다고 가정
2. 모든 단어에 k개 토픽 중 하나를 임의 할당
3. 임의 할당했지만 올바르게 할당되었다고 가정
4. 다음 과정을 반복하여 토픽을 재할당
   - p(z|d) : 문서 d의 단어들 중 토픽 z에 해당하는 단어의 비율
   - p(w|z) : 전체 문서에서 토픽 z가 할당된 모든 단어 중 단어 w의 비율
   - p(w|z) * p(z|d)에 따라 토픽 z를 할당
5. 안정적인 상태가 될 때까지 반복



### 감성분석

> 문서, 단락, 문장 내에서 극성을 감지하는 텍스트 분석 방법
>
> > __감정 감지__와 __특성 기반 감정분석__이 있다

#### 필요성

- 대랑 데이터 처리 가능
- 추출의 일관성
- 실시간 분석 가능

#### 활용 예

- SNS 모니터링
- 브랜드 모니터링
- VoC

#### 감정분석 방법

- 사전기반 감정분석
- 나이브베이즈 분류기 활용 감정분석



## 텍스트 마이닝

텍스트 데이터를 통해 의사결정에 유용한 정보나 텍스트 패턴을 도출하는 과정으로 인공지능, 통계학, 빅데이터 분석을 아우르는 여러분야가 융합된 분석 방법

전처리 과정 대부분이 자연어 문서로부터 의미 있는 특징을 추출하는데 집중

비정형 데이터를 정형화된 형태로 바꾸는 과정은 데이터 마이닝에서는 볼 수 없는 텍스트 마이닝만의 과정임.

- 활용 사례

  - 법률 문서 검토
  - 정보 요약
  - 실시간 리뷰 모니터링
  - 경쟁사 분석
  - 뉴스레터 메일링/SNS 자동 포스팅
  - 고객 분석

  